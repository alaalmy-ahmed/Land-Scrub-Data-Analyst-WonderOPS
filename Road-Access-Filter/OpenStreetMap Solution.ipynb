{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**\n",
    "\n",
    "* **Precision (No): 0.76** \n",
    "    - Out of all the instances your model predicted as \"No\" (no road access), 76% of them were actually correct.\n",
    "    - This indicates a moderate rate of false positives for the \"No\" class, meaning the model sometimes predicts no access when there actually is.\n",
    "\n",
    "* **Recall (No): 0.89** \n",
    "    - Out of all the instances that truly had \"No\" road access, your model was able to correctly identify 89% of them.\n",
    "    - This suggests a relatively low rate of false negatives for the \"No\" class, meaning the model is good at catching instances without road access.\n",
    "\n",
    "* **F1-score (No): 0.82** \n",
    "    - The F1-score is the harmonic mean of precision and recall, providing a balanced measure of the model's performance on the \"No\" class.\n",
    "    - An F1-score of 0.82 is considered good, showing a decent balance between correctly identifying instances without access and minimizing false positives.\n",
    "\n",
    "* **Precision (Yes): 0.89**\n",
    "    - Out of all the instances your model predicted as \"Yes\" (having road access), 89% of them were actually correct.\n",
    "    - This implies a low rate of false positives for the \"Yes\" class.\n",
    "\n",
    "* **Recall (Yes): 0.77**\n",
    "    - Out of all the instances that truly had road access, your model was able to correctly identify 77% of them.\n",
    "    - This indicates a somewhat higher rate of false negatives for the \"Yes\" class compared to the \"No\" class, meaning the model might miss some properties that do have road access\n",
    "\n",
    "* **F1-score (Yes): 0.83**\n",
    "    - The F1-score for the \"Yes\" class is 0.83, demonstrating good overall performance but slightly lower than the \"No\" class due to the lower recall.\n",
    "\n",
    "* **Accuracy: 0.82**\n",
    "    - Overall, your model correctly classified 82% of the properties in the dataset, regardless of their actual road access status.\n",
    "\n",
    "* **Macro avg & Weighted avg:** \n",
    "    - These are average scores across both classes, calculated differently.\n",
    "    - **Macro avg** gives equal weight to both classes, even if they have imbalanced support (different number of samples).\n",
    "    - **Weighted avg** takes into account the number of samples in each class, giving more weight to the class with more samples.\n",
    "    - In this case, both averages are around 0.82-0.83, suggesting a fairly balanced performance across both classes.\n",
    "\n",
    "**Confusion Matrix**\n",
    "\n",
    "* The confusion matrix provides a more detailed look at the model's predictions.\n",
    "* **True Positives (TP): 100** - The model correctly predicted 100 properties as having road access.\n",
    "* **True Negatives (TN): 94** - The model correctly predicted 94 properties as having no road access\n",
    "* **False Positives (FP): 30** - The model incorrectly predicted 30 properties as having road access when they didn't\n",
    "* **False Negatives (FN): 12** - The model incorrectly predicted 12 properties as having no road access when they actually did\n",
    "\n",
    "**Overall Interpretation:**\n",
    "\n",
    "* Your model demonstrates a good overall performance in predicting road access, with an accuracy of 82%.\n",
    "* It's particularly strong at identifying properties **without** road access, as evidenced by the high recall (0.89) and F1-score (0.82) for the \"No\" class\n",
    "* There is room for improvement in identifying properties **with** road access, as the recall for the \"Yes\" class is slightly lower (0.77).\n",
    "\n",
    "**Potential Next Steps:**\n",
    "\n",
    "* If the focus is on correctly identifying properties *without* road access, the model is already doing a good job. You could further fine-tune it to improve precision for the \"No\" class if minimizing false positives is crucial.\n",
    "* If identifying properties *with* road access is more important, you could try techniques to improve the recall for the \"Yes\" class. This might involve adjusting the model's parameters, using a different algorithm, or gathering more data for properties with road access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Road access Testing Data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 138\u001b[0m\n\u001b[0;32m    135\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered and cleaned properties saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 82\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Load the Excel file\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     excel_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRoad access Testing Data.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 82\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcel_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Use a sample of 50 rows for testing\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# df = df.sample(n=100, random_state=42)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Ensure the ACREAGE column is numeric and drop rows with NaN values\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACREAGE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACREAGE\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ak758\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ak758\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1563\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ak758\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1417\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1421\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1422\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1423\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ak758\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Road access Testing Data.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from math import sqrt, pi\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, f1_score, precision_score, \n",
    "    recall_score, cohen_kappa_score, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def calculate_radius(acre, margin=1.5):\n",
    "    \"\"\"Calculate the radius of a circle with the same area as the property in acres.\"\"\"\n",
    "    return sqrt(acre * 4046.86 / pi) * margin\n",
    "\n",
    "def check_road_access(lat, lon, radius, retries=3):\n",
    "    \"\"\"Check if the property has road access within the calculated radius.\"\"\"\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    overpass_query = f\"\"\"\n",
    "    [out:json];\n",
    "    way(around:{radius},{lat},{lon})[\"highway\"];\n",
    "    out body;\n",
    "    \"\"\"\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(overpass_url, params={'data': overpass_query}, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            return bool(data.get('elements'))\n",
    "        except (requests.RequestException, ValueError) as e:\n",
    "            logging.warning(f\"Request failed (attempt {attempt + 1}/{retries}): {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(1)  # Retry after a short delay\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "def check_road_access_weighted(lat, lon, acre, margins, weights):\n",
    "    \"\"\"Check road access using weighted margins.\"\"\"\n",
    "    score = 0\n",
    "    for margin, weight in zip(margins, weights):\n",
    "        radius = calculate_radius(acre, margin)\n",
    "        if check_road_access(lat, lon, radius):\n",
    "            score += weight\n",
    "        # time.sleep(1)  # Short delay to avoid overwhelming the API\n",
    "    \n",
    "    # Determine the final access based on the accumulated score\n",
    "    return 'Yes' if score >= sum(weights) / 3 else 'No'\n",
    "\n",
    "def filter_properties_with_weighted_road_access(df):\n",
    "    \"\"\"Filter properties based on weighted road access prediction.\"\"\"\n",
    "    margins = np.arange(0.0, 3.1, 0.25)\n",
    "    weights = np.linspace(1.0, 0.1, len(margins))\n",
    "    return [check_road_access_weighted(row['LATITUDE'], row['LONGITUDE'], row['ACREAGE'], margins, weights) for _, row in df.iterrows()]\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion Matrix', cmap='Blues', normalize=True):\n",
    "    \"\"\"Plot the confusion matrix using seaborn.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd', cmap=cmap, cbar=False, \n",
    "                xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(f'{title}\\nAccuracy={np.trace(cm)/np.sum(cm):.4f}')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "def clean_final_sheet(df):\n",
    "    \"\"\"Clean up the final DataFrame by identifying the correct 'Road access' column and removing duplicates.\"\"\"\n",
    "    road_access_columns = [col for col in df.columns if 'Road access' in col]\n",
    "    df = df.drop(columns=road_access_columns[1:])\n",
    "    df.rename(columns={road_access_columns[0]: 'Road access'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Load the Excel file\n",
    "    excel_file_path = 'Road access Testing Data.xlsx'\n",
    "    df = pd.read_excel(excel_file_path)\n",
    "\n",
    "    # Use a sample of 50 rows for testing\n",
    "    # df = df.sample(n=100, random_state=42)\n",
    "\n",
    "    # Ensure the ACREAGE column is numeric and drop rows with NaN values\n",
    "    df['ACREAGE'] = pd.to_numeric(df['ACREAGE'], errors='coerce')\n",
    "    df = df.dropna(subset=['ACREAGE'])\n",
    "\n",
    "    # Get the actual and predicted road access values\n",
    "    actual_access = df['Road access'].tolist()\n",
    "    predicted_access = filter_properties_with_weighted_road_access(df)\n",
    "\n",
    "    # Generate and log the classification report\n",
    "    report = classification_report(actual_access, predicted_access, target_names=['No', 'Yes'])\n",
    "    logging.info(f\"Classification Report:\\n{report}\")\n",
    "\n",
    "    # Save the classification report to a text file\n",
    "    report_file = f\"{excel_file_path.split('.')[0]}_Classification_Report.txt\"\n",
    "    with open(report_file, \"w\") as file:\n",
    "        file.write(\"Classification Report:\\n\")\n",
    "        file.write(report)\n",
    "\n",
    "    # Generate and log the confusion matrix\n",
    "    cm = confusion_matrix(actual_access, predicted_access, labels=['No', 'Yes'])\n",
    "    logging.info(f\"Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plot_confusion_matrix(cm, target_names=['No', 'Yes'])\n",
    "\n",
    "    # Fit the LabelBinarizer on the actual labels\n",
    "    lb = LabelBinarizer()\n",
    "    actual_binarized = lb.fit_transform(actual_access)\n",
    "    predicted_binarized = lb.transform(predicted_access)\n",
    "\n",
    "    # Additional performance metrics\n",
    "    precision = precision_score(actual_access, predicted_access, pos_label='Yes')\n",
    "    recall = recall_score(actual_access, predicted_access, pos_label='Yes')\n",
    "    f1 = f1_score(actual_access, predicted_access, pos_label='Yes')\n",
    "    kappa = cohen_kappa_score(actual_access, predicted_access)\n",
    "    auc = roc_auc_score(actual_binarized, predicted_binarized)\n",
    "\n",
    "    logging.info(f\"Precision (Yes): {precision:.4f}\")\n",
    "    logging.info(f\"Recall (Yes): {recall:.4f}\")\n",
    "    logging.info(f\"F1 Score (Yes): {f1:.4f}\")\n",
    "    logging.info(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "    logging.info(f\"AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "    # Filter and save properties with road access\n",
    "    df['Predicted Road Access'] = predicted_access\n",
    "    cleaned_filtered_df = clean_final_sheet(df[df['Predicted Road Access'] == 'Yes'])\n",
    "    output_file_path = f\"{excel_file_path.split('.')[0]}_FILTERED_CLEANED.xlsx\"\n",
    "    cleaned_filtered_df.to_excel(output_file_path, index=False)\n",
    "    logging.info(f\"Filtered and cleaned properties saved to {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering properties: 100%|██████████| 83/83 [05:34<00:00,  4.03s/it]\n",
      "2024-08-22 22:58:37,500 - INFO - Filtered Road-Access properties saved to Export-Baldwin-MI-target-rocket_ROAD-ACCESS_FILTERED.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from math import sqrt, pi\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def calculate_radius(acre, margin=1.5):\n",
    "    \"\"\"Calculate the radius of a circle with the same area as the property in acres.\"\"\"\n",
    "    return sqrt(acre * 4046.86 / pi) * margin\n",
    "\n",
    "def check_road_access(lat, lon, radius, retries=3):\n",
    "    \"\"\"Check if the property has road access within the calculated radius.\"\"\"\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    overpass_query = f\"\"\"\n",
    "    [out:json];\n",
    "    way(around:{radius},{lat},{lon})[\"highway\"];\n",
    "    out body;\n",
    "    \"\"\"\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(overpass_url, params={'data': overpass_query}, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            return bool(data.get('elements'))\n",
    "        except (requests.RequestException, ValueError) as e:\n",
    "            logging.warning(f\"Request failed (attempt {attempt + 1}/{retries}): {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(1)  # Retry after a short delay\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "def check_road_access_weighted(lat, lon, acre, margins, weights):\n",
    "    \"\"\"Check road access using weighted margins.\"\"\"\n",
    "    score = 0\n",
    "    for margin, weight in zip(margins, weights):\n",
    "        radius = calculate_radius(acre, margin)\n",
    "        if check_road_access(lat, lon, radius):\n",
    "            score += weight\n",
    "    \n",
    "    # Calculate the percentage score\n",
    "    percentage_score = round(score / sum(weights), 3)\n",
    "    \n",
    "    # Determine the final access based on the accumulated score\n",
    "    road_access = 'Yes' if score >= sum(weights) / 3 else 'No'\n",
    "    \n",
    "    return road_access, percentage_score\n",
    "\n",
    "def filter_properties_with_weighted_road_access(df):\n",
    "    \"\"\"Filter properties based on weighted road access prediction and return road access and score.\"\"\"\n",
    "    margins = np.arange(0.0, 3.1, 0.25)\n",
    "    weights = np.linspace(1.0, 0.1, len(margins))\n",
    "    \n",
    "    results = [check_road_access_weighted(row['LATITUDE'], row['LONGITUDE'], row['ACREAGE'], margins, weights)\n",
    "               for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Filtering properties\")]\n",
    "    \n",
    "    df['Road-Access'], df['Percentage'] = zip(*results)\n",
    "    return df\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion Matrix', cmap='Blues', normalize=True):\n",
    "    \"\"\"Plot the confusion matrix using seaborn.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd', cmap=cmap, cbar=False, \n",
    "                xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(f'{title}\\nAccuracy={np.trace(cm)/np.sum(cm):.4f}')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "def clean_final_sheet(df):\n",
    "    \"\"\"Clean up the final DataFrame by identifying the correct 'Road access' column and removing duplicates.\"\"\"\n",
    "    road_access_columns = [col for col in df.columns if 'Road access' in col]\n",
    "    df = df.drop(columns=road_access_columns[1:])\n",
    "    df.rename(columns={road_access_columns[0]: 'Road access'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Load the Excel file\n",
    "    excel_file_path = 'Export-Baldwin-MI-target-rocket.xlsx SCRUBBED.xlsx'\n",
    "    df = pd.read_excel(excel_file_path)\n",
    "\n",
    "    # Ensure the ACREAGE column is numeric and drop rows with NaN values\n",
    "    df['ACREAGE'] = pd.to_numeric(df['ACREAGE'], errors='coerce')\n",
    "    df = df.dropna(subset=['ACREAGE'])\n",
    "\n",
    "    # Filter properties based on road access and calculate percentage score\n",
    "    df = filter_properties_with_weighted_road_access(df)\n",
    "\n",
    "    # Save the DataFrame with road access and percentage columns\n",
    "    output_file_path = f\"{excel_file_path.split('.')[0]}_WITH_ROAD_ACCESS.xlsx\"\n",
    "    df.to_excel(output_file_path, index=False)\n",
    "    logging.info(f\"Filtered properties saved to {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
